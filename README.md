# ğŸš¢ Titanic â€” Projeto de Machine Learning (ClassificaÃ§Ã£o)

Autores: 5MLET â€” Anderson, Beatriz, Marianna, Murilo, Welder
Data: 2025
Linguagem: Python 3.x
Ambiente: Google Colab / Jupyter Notebook

## 1. DescriÃ§Ã£o do Projeto

O objetivo deste projeto Ã© prever a probabilidade de sobrevivÃªncia dos passageiros do Titanic com base em caracterÃ­sticas demogrÃ¡ficas e de viagem, utilizando tÃ©cnicas de aprendizado supervisionado.

O problema Ã© tratado como uma classificaÃ§Ã£o binÃ¡ria, onde:

0 â†’ passageiro nÃ£o sobreviveu

1 â†’ passageiro sobreviveu

A base de dados Ã© proveniente do Kaggle Titanic Challenge, amplamente usada em estudos introdutÃ³rios de Machine Learning.

## 2. Estrutura do Projeto

```text
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ titanic_best_<modelo>_<timestamp>.joblib
â”œâ”€â”€ tc3_titanic_survival_test_3.py
â””â”€â”€ README.md
```
data/: contÃ©m os datasets originais do Kaggle.

artifacts/: armazena o pipeline treinado (.joblib).

tc3_titanic_survival_test_3.py: cÃ³digo principal do projeto.

3. Principais DependÃªncias
pip install numpy pandas scikit-learn matplotlib seaborn gradio joblib

Bibliotecas utilizadas:

pandas / numpy: manipulaÃ§Ã£o de dados

matplotlib / seaborn: visualizaÃ§Ã£o

scikit-learn: prÃ©-processamento, modelagem e mÃ©tricas

joblib: serializaÃ§Ã£o de modelos

gradio: criaÃ§Ã£o de interface web interativa

4. Fluxo do Projeto
Etapa 1 â€” Carregamento dos Dados

Os arquivos train.csv e test.csv devem estar na pasta data/.

df = pd.read_csv("data/train.csv")


O script verifica automaticamente se os arquivos estÃ£o disponÃ­veis antes de prosseguir.

Etapa 2 â€” AnÃ¡lise ExploratÃ³ria (EDA)

Foram criados diversos grÃ¡ficos e tabelas para identificar padrÃµes, como:

DistribuiÃ§Ã£o de sobreviventes (Survived)

Taxa de sobrevivÃªncia por sexo, classe e porto de embarque

DistribuiÃ§Ã£o de idade entre sobreviventes e nÃ£o sobreviventes

RelaÃ§Ã£o entre tamanho da famÃ­lia e chance de sobrevivÃªncia

Mapa de correlaÃ§Ã£o entre variÃ¡veis numÃ©ricas

Principais insights:

Mulheres tiveram taxa de sobrevivÃªncia significativamente maior.

Passageiros da 1Âª classe tiveram melhores chances.

O porto de embarque 'C' apresentou a maior taxa de sobrevivÃªncia.

FamÃ­lias com 3 pessoas tiveram, em mÃ©dia, as maiores chances de sobrevivÃªncia.

Etapa 3 â€” PrÃ©-processamento

Etapas principais:

RemoÃ§Ã£o de colunas pouco informativas: PassengerId, Name, Ticket, Cabin

CriaÃ§Ã£o da feature FamilySize = SibSp + Parch + 1

SeparaÃ§Ã£o entre features (X) e target (y)

ImputaÃ§Ã£o de nulos:

NumÃ©ricas â†’ median

CategÃ³ricas â†’ most_frequent

CodificaÃ§Ã£o: OneHotEncoder para variÃ¡veis categÃ³ricas

NormalizaÃ§Ã£o: StandardScaler em variÃ¡veis numÃ©ricas

DivisÃ£o do dataset em train/test (80/20), com stratify=y

Etapa 4 â€” Modelagem

Modelos treinados:

Logistic Regression

Decision Tree

Random Forest

Todos foram implementados dentro de pipelines (sklearn.pipeline.Pipeline) contendo o prÃ©-processamento + modelo.

Pipeline([
    ("preprocess", preprocess),
    ("model", RandomForestClassifier(...))
])

Etapa 5 â€” AvaliaÃ§Ã£o

Cada modelo foi avaliado no conjunto de teste com as mÃ©tricas:

Accuracy

Precision

Recall

F1-score

Matriz de confusÃ£o

Os resultados sÃ£o exibidos em uma tabela comparativa com coloraÃ§Ã£o gradiente (.style.background_gradient).

Etapa 6 â€” ValidaÃ§Ã£o Cruzada (K-Fold)

Uma validaÃ§Ã£o cruzada estratificada (K=5) Ã© executada para avaliar a estabilidade dos modelos.
MÃ©trica principal: F1-score mÃ©dio e desvio padrÃ£o.

Etapa 7 â€” Interpretabilidade

O modelo com melhor F1 Ã© selecionado.

Se RandomForest: Ã© exibida a importÃ¢ncia das features.

Se LogisticRegression: sÃ£o exibidos os coeficientes dos preditores (sinal e magnitude).

Isso permite identificar as variÃ¡veis mais influentes na decisÃ£o.

Etapa 8 â€” ExportaÃ§Ã£o do Modelo

O melhor pipeline (prÃ©-processamento + modelo) Ã© salvo automaticamente em:

artifacts/titanic_best_<Modelo>_<timestamp>.joblib


Assim, ele pode ser reutilizado sem necessidade de reprocessar os dados.

Etapa 9 â€” InferÃªncia

Um exemplo de prediÃ§Ã£o Ã© demonstrado:

sample = pd.DataFrame([{
    "Pclass": 3, "Sex": "male", "Age": 34,
    "SibSp": 1, "Parch": 0, "Fare": 7.25, "Embarked": "S"
}])


O modelo estima a probabilidade e retorna mensagens como:

âœ… Sobreviveria (probabilidade: 83.4%)
âŒ NÃ£o sobreviveria (probabilidade: 27.1%)

Etapa 10 â€” AplicaÃ§Ã£o Web (Gradio)

Uma interface interativa foi criada com Gradio:

O usuÃ¡rio escolhe valores via dropdowns e sliders.

O modelo retorna a previsÃ£o com uma barra de probabilidade colorida.

O app pode ser executado localmente ou compartilhado via link pÃºblico.

Exemplo:

interface.launch(share=True)

5. MÃ©tricas Esperadas (exemplo tÃ­pico)
Modelo	Accuracy	Precision	Recall	F1
RandomForest	0.83	0.81	0.80	0.80
Logistic Regression	0.80	0.78	0.77	0.77
Decision Tree	0.77	0.75	0.74	0.74

(os valores exatos dependem da semente e do dataset local)

6. ConclusÃµes

O Random Forest apresentou o melhor desempenho geral, equilibrando precisÃ£o e recall.

As variÃ¡veis mais determinantes foram Sexo, Classe (Pclass), Idade, e Tarifa (Fare).

O projeto ilustra o ciclo completo de Machine Learning â€” da anÃ¡lise inicial Ã  aplicaÃ§Ã£o prÃ¡tica.
